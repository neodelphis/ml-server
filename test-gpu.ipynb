{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten , Conv2D, Dropout, BatchNormalization, ReLU\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from math import trunc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "\n",
    "# Ajout de l'indication du canal sur le images pour le traitement via réseau convolutionnel\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], 28, 28, 1)\n",
    "\n",
    "input_shape=(28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "# normalisation\n",
    "x_train, x_val = x_train/255., x_val/255.\n",
    "# 1-hot encoding\n",
    "y_train, y_val = to_categorical(y_train, dtype='int8'), to_categorical(y_val, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "#\n",
    "# Nombre d'époques pour l'apprentissage:\n",
    "epochs = 30\n",
    "\n",
    "# Taille du batch d'entraînement:\n",
    "batch_size = 100\n",
    "\n",
    "# Taux de dropout rate\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Planification de l'apprentissage\n",
    "initial_learning_rate = 0.005\n",
    "# taux de décroissance du pas d'apprentissage\n",
    "decay_rate = 0.7\n",
    "# Nombre d'époques à faire avant de changer de pas\n",
    "decay_steps = 180000 # 3 époques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure du modèle\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(12, kernel_size=(6,6), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(12, (5,5), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(24, (4,4), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planification de l'apprentissage\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate,\n",
    "            decay_steps = decay_steps,\n",
    "            decay_rate = decay_rate,\n",
    "            staircase=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heure_de_debut = time.time()\n",
    "historique = model.fit(x_train, y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=epochs,\n",
    "                       verbose=1,\n",
    "                       validation_data=(x_val, y_val))\n",
    "\n",
    "temps_de_calcul = time.time() - heure_de_debut\n",
    "print(\"Temps de calcul: {:d} s\".format(trunc(temps_de_calcul)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation des résultats\n",
    "accuracy_train = historique.history['accuracy']\n",
    "accuracy_test = historique.history['val_accuracy']\n",
    "loss_train = historique.history['loss']\n",
    "loss_test = historique.history['val_loss']\n",
    "# Précision\n",
    "plt.plot(accuracy_test, c='coral', label='test')\n",
    "plt.plot(accuracy_train, c='steelblue', label='val')\n",
    "plt.xlabel('Epoque')\n",
    "plt.title('Précision')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()\n",
    "# Fonction de coût\n",
    "plt.plot(loss_test, c='coral', label='test')\n",
    "plt.plot(loss_train, c='steelblue', label='val')\n",
    "plt.title('Fonction de coût')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
